{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0dff1b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8901e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import gensim.downloader\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434a0e5",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e8a198-92c0-4eb3-bc62-435c35a70434",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "\n",
    "\n",
    "def word_tokenize(s: str):\n",
    "    return [x.lower() for x in word_tokenize_pattern.findall(s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e61b3",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb3292a6-f7ab-4858-9732-76ba312fe93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EMOTIONS = [\"Angry\", \"Happy\", \"Relaxed\", \"Sad\"]\n",
    "metrics_result = []\n",
    "emotions_metric_result = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def print_results(gold_labels, predicted_labels, model_name = \"\", display = True):\n",
    "    # overall\n",
    "    p, r, f, _ = precision_recall_fscore_support(\n",
    "        gold_labels, predicted_labels, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(gold_labels, predicted_labels)\n",
    "\n",
    "    result = {\"Model\": model_name, \"Precision\": p, \"Recall\": r, \"F1\": f, \"Accuracy\": acc}\n",
    "    \n",
    "\n",
    "    index_found = next((i for i, d in enumerate(metrics_result) if d.get('Model') == model_name), None)\n",
    "\n",
    "    if (index_found == None):\n",
    "        metrics_result.append(result)\n",
    "    else:\n",
    "        metrics_result[index_found] = result\n",
    "\n",
    "    df_all = pd.DataFrame(metrics_result)\n",
    "  \n",
    "    if (display == True):\n",
    "        print(\"=== Overall (Macro Avg) ===\")\n",
    "        # print(\"Precision:\", p)\n",
    "        # print(\"Recall:\", r)\n",
    "        # print(\"F1:\", f)\n",
    "        # print(\"Accuracy:\", acc)\n",
    "        # print(metrics_result)\n",
    "        print(df_all.to_string(index=False))\n",
    "        print()\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    # Per-emotion metrics\n",
    "    p_i, r_i, f_i, _ = precision_recall_fscore_support(\n",
    "        gold_labels, predicted_labels, average=None, zero_division=0\n",
    "    )\n",
    "    if (display == True):\n",
    "        print(\"=== Per Emotion (Class) Metrics ===\")\n",
    "    for i, emotion in enumerate(EMOTIONS):\n",
    "        # print(\"  Precision:\", p_i[i])\n",
    "        # print(\"  Recall:   \", r_i[i])\n",
    "        # print(\"  F1:       \", f_i[i])\n",
    "        emotion_result = {\"Model\": model_name, \"Emotion\": emotion, \"Precision\": p_i[i], \"Recall\": r_i[i], \"F1\": f_i[i]}\n",
    "        emotion_index_found = next((i for i, d in enumerate(emotions_metric_result) if d.get('Model') == model_name and d.get(\"Emotion\" == emotion)), None)\n",
    "\n",
    "        if (emotion_index_found == None):\n",
    "            emotions_metric_result.append(emotion_result)\n",
    "        else:\n",
    "            emotions_metric_result[emotion_index_found] = emotion_result\n",
    "        df_emotions = pd.DataFrame(emotions_metric_result)\n",
    "        filtered_df = df_emotions[df_emotions['Emotion'] == emotion]\n",
    "        if (display == True):\n",
    "            print(f\"{emotion}:\")\n",
    "            print(filtered_df.to_string(index=False))\n",
    "            print()\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "\n",
    "    p, r, f, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"precision\": p, \"recall\": r, \"f1\": f, \"accuracy\": acc}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b4b6e",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4edfab4b-46e2-464a-a47f-a2bb86f62c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"NJU_MusicMood_v1.0\"\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(EMOTIONS)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "timestamp_pattern = re.compile(r\"\\[\\d{2}:\\d{2}(?:\\.\\d{2})?\\]\")\n",
    "\n",
    "\n",
    "def clean_lyrics(text: str) -> str:\n",
    "    # Remove timestamps like [00:29]\n",
    "    text = timestamp_pattern.sub(\"\", text)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Normalize quotes\n",
    "    text = text.replace(\"’\", \"'\").replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "\n",
    "    # Remove ellipses and repeated dots\n",
    "    text = re.sub(r\"\\.{2,}\", \" \", text)\n",
    "\n",
    "    # Remove long underscores\n",
    "    text = re.sub(r\"_{2,}\", \" \", text)\n",
    "\n",
    "    # Remove trailing \"end\" markers at the end of the file\n",
    "    text = re.sub(r\"\\bend[.\\s]*$\", \"\", text.strip())\n",
    "\n",
    "    # Replace newlines with space\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    # Keep only letters, digits, spaces, apostrophes\n",
    "    text = re.sub(r\"[^a-z0-9' ]+\", \" \", text)\n",
    "\n",
    "    # Collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "def get_lyrics(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "    return clean_lyrics(raw)\n",
    "\n",
    "\n",
    "def get_lyrics_and_labels(split: str):\n",
    "    texts, labels = [], []\n",
    "    for emotion in EMOTIONS:\n",
    "        folder = os.path.join(DATASET_DIR, emotion, split)\n",
    "        if not os.path.isdir(folder):\n",
    "            continue\n",
    "\n",
    "        for fname in os.listdir(folder):\n",
    "            if not fname.endswith(\".txt\"):\n",
    "                continue\n",
    "            if fname.lower() == \"info.txt\":\n",
    "                continue\n",
    "\n",
    "            path = os.path.join(folder, fname)\n",
    "            txt = get_lyrics(path)\n",
    "            if txt.strip():\n",
    "                texts.append(txt)\n",
    "                labels.append(emotion)\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "# Load data \n",
    "train_texts, train_labels = get_lyrics_and_labels(\"Train\")\n",
    "dev_texts, dev_labels = get_lyrics_and_labels(\"Test\")\n",
    "\n",
    "assert len(train_texts) == len(train_labels)\n",
    "assert len(dev_texts) == len(dev_labels)\n",
    "\n",
    "# Datasets\n",
    "train_ds = Dataset.from_dict(\n",
    "    {\"text\": train_texts, \"label\": [label2id[l] for l in train_labels]}\n",
    ")\n",
    "dev_ds = Dataset.from_dict(\n",
    "    {\"text\": dev_texts, \"label\": [label2id[l] for l in dev_labels]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f93414e",
   "metadata": {},
   "source": [
    "## Baseline: Bag of Words & Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5a40396-55f3-43dc-af8e-fd45ad82c685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline: Bag of Words & Logistic Regression ===\n",
      "=== Overall (Macro Avg) ===\n",
      "   Model  Precision   Recall       F1  Accuracy\n",
      "BoW & LR   0.380262 0.372645 0.373144  0.363395\n",
      "\n",
      "=== Per Emotion (Class) Metrics ===\n",
      "Angry:\n",
      "   Model Emotion  Precision   Recall       F1\n",
      "BoW & LR   Angry   0.492958 0.492958 0.492958\n",
      "\n",
      "Happy:\n",
      "   Model Emotion  Precision   Recall       F1\n",
      "BoW & LR   Happy    0.45679 0.349057 0.395722\n",
      "\n",
      "Relaxed:\n",
      "   Model Emotion  Precision  Recall       F1\n",
      "BoW & LR Relaxed   0.305344 0.39604 0.344828\n",
      "\n",
      "Sad:\n",
      "   Model Emotion  Precision   Recall       F1\n",
      "BoW & LR     Sad   0.265957 0.252525 0.259067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Baseline: Bag of Words & Logistic Regression ===\")\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer=word_tokenize)\n",
    "train_counts = count_vectorizer.fit_transform(train_texts)\n",
    "dev_counts = count_vectorizer.transform(dev_texts)\n",
    "\n",
    "lr_bow = LogisticRegression(max_iter=500, random_state=0)\n",
    "lr_bow.fit(train_counts, train_labels)\n",
    "\n",
    "lr_bow_dev_predictions = lr_bow.predict(dev_counts)\n",
    "print_results(dev_labels, lr_bow_dev_predictions, \"BoW & LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bab194",
   "metadata": {},
   "source": [
    "## Baseline 2: Word2Vec & Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e417a9d1-ef6c-4527-a6dc-49d0e591d404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Word2Vec & Logistic Regression ===\n",
      "=== Overall (Macro Avg) ===\n",
      "        Model  Precision   Recall       F1  Accuracy\n",
      "     BoW & LR   0.380262 0.372645 0.373144  0.363395\n",
      "Word2Vec & LR   0.461446 0.478161 0.455341  0.453581\n",
      "\n",
      "=== Per Emotion (Class) Metrics ===\n",
      "Angry:\n",
      "        Model Emotion  Precision   Recall       F1\n",
      "     BoW & LR   Angry   0.492958 0.492958 0.492958\n",
      "Word2Vec & LR   Angry   0.612903 0.802817 0.695122\n",
      "\n",
      "Happy:\n",
      "        Model Emotion  Precision   Recall       F1\n",
      "     BoW & LR   Happy   0.456790 0.349057 0.395722\n",
      "Word2Vec & LR   Happy   0.480392 0.462264 0.471154\n",
      "\n",
      "Relaxed:\n",
      "        Model Emotion  Precision   Recall       F1\n",
      "     BoW & LR Relaxed   0.305344 0.396040 0.344828\n",
      "Word2Vec & LR Relaxed   0.335821 0.445545 0.382979\n",
      "\n",
      "Sad:\n",
      "        Model Emotion  Precision   Recall       F1\n",
      "     BoW & LR     Sad   0.265957 0.252525 0.259067\n",
      "Word2Vec & LR     Sad   0.416667 0.202020 0.272109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Word2Vec & Logistic Regression ===\")\n",
    "\n",
    "w2v_model = gensim.downloader.load(\"word2vec-google-news-300\")\n",
    "VECTOR_SIZE = w2v_model.vector_size\n",
    "\n",
    "\n",
    "def vec_for_doc(tokenized_doc):\n",
    "    vectors = [w2v_model[word] for word in tokenized_doc if word in w2v_model.key_to_index]\n",
    "    if not vectors:\n",
    "        return np.zeros(VECTOR_SIZE, dtype=\"float32\")\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "\n",
    "train_vecs = [vec_for_doc(word_tokenize(x)) for x in train_texts]\n",
    "dev_vecs = [vec_for_doc(word_tokenize(x)) for x in dev_texts]\n",
    "\n",
    "lr_w2v = LogisticRegression(max_iter=500, random_state=0)\n",
    "lr_w2v.fit(train_vecs, train_labels)\n",
    "\n",
    "w2v_dev_predictions = lr_w2v.predict(dev_vecs)\n",
    "print_results(dev_labels, w2v_dev_predictions, \"Word2Vec & LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21eee90",
   "metadata": {},
   "source": [
    "## Split lyrics into start middle end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d39a0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment(text, segment=\"start\", portion=0.3):\n",
    "    \"\"\"\n",
    "    Extract a portion of the lyrics.\n",
    "    portion=0.3 means 30% of tokens.\n",
    "    segment can be \"start\", \"middle\", or \"end\".\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    n = len(tokens)\n",
    "    if n == 0:\n",
    "        return \"\"\n",
    "\n",
    "    cut = int(n * portion)  # number of tokens for start/end\n",
    "\n",
    "    if segment == \"start\":\n",
    "        return \" \".join(tokens[:cut])\n",
    "\n",
    "    elif segment == \"middle\":\n",
    "        start = int(n * 0.35)\n",
    "        end = int(n * 0.65)\n",
    "        return \" \".join(tokens[start:end])\n",
    "\n",
    "    elif segment == \"end\":\n",
    "        return \" \".join(tokens[-cut:])\n",
    "\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "\n",
    "# Build dev\n",
    "dev_start_texts = [get_segment(t, \"start\") for t in dev_texts]\n",
    "dev_middle_texts = [get_segment(t, \"middle\") for t in dev_texts]\n",
    "dev_end_texts = [get_segment(t, \"end\") for t in dev_texts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c423049",
   "metadata": {},
   "source": [
    "## Evaluate BoW model Segmented Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01c265a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BoW Logistic Regression: Position-based Evaluation (NO retraining) ===\n",
      "=== Overall (Macro Avg) ===\n",
      "               Model  Precision   Recall       F1  Accuracy\n",
      "            BoW & LR   0.380262 0.372645 0.373144  0.363395\n",
      "       Word2Vec & LR   0.461446 0.478161 0.455341  0.453581\n",
      " BoW Segmented_START   0.414294 0.320851 0.275773  0.323607\n",
      "BoW Segmented_MIDDLE   0.405777 0.314621 0.274071  0.318302\n",
      "   BoW Segmented_END   0.341373 0.301432 0.271661  0.307692\n",
      "\n",
      "=== Per Emotion (Class) Metrics ===\n",
      "Angry:\n",
      "               Model Emotion  Precision   Recall       F1\n",
      "            BoW & LR   Angry   0.492958 0.492958 0.492958\n",
      "       Word2Vec & LR   Angry   0.612903 0.802817 0.695122\n",
      " BoW Segmented_START   Angry   0.575758 0.267606 0.365385\n",
      "BoW Segmented_MIDDLE   Angry   0.562500 0.253521 0.349515\n",
      "   BoW Segmented_END   Angry   0.441176 0.211268 0.285714\n",
      "\n",
      "Happy:\n",
      "               Model Emotion  Precision   Recall       F1\n",
      "            BoW & LR   Happy   0.456790 0.349057 0.395722\n",
      "       Word2Vec & LR   Happy   0.480392 0.462264 0.471154\n",
      " BoW Segmented_START   Happy   0.600000 0.113208 0.190476\n",
      "BoW Segmented_MIDDLE   Happy   0.538462 0.132075 0.212121\n",
      "   BoW Segmented_END   Happy   0.414634 0.160377 0.231293\n",
      "\n",
      "Relaxed:\n",
      "               Model Emotion  Precision   Recall       F1\n",
      "            BoW & LR Relaxed   0.305344 0.396040 0.344828\n",
      "       Word2Vec & LR Relaxed   0.335821 0.445545 0.382979\n",
      " BoW Segmented_START Relaxed   0.295374 0.821782 0.434555\n",
      "BoW Segmented_MIDDLE Relaxed   0.279720 0.792079 0.413437\n",
      "   BoW Segmented_END Relaxed   0.291498 0.712871 0.413793\n",
      "\n",
      "Sad:\n",
      "               Model Emotion  Precision   Recall       F1\n",
      "            BoW & LR     Sad   0.265957 0.252525 0.259067\n",
      "       Word2Vec & LR     Sad   0.416667 0.202020 0.272109\n",
      " BoW Segmented_START     Sad   0.186047 0.080808 0.112676\n",
      "BoW Segmented_MIDDLE     Sad   0.242424 0.080808 0.121212\n",
      "   BoW Segmented_END     Sad   0.218182 0.121212 0.155844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== BoW Logistic Regression: Position-based Evaluation (NO retraining) ===\")\n",
    "\n",
    "# START\n",
    "dev_start_counts = count_vectorizer.transform(dev_start_texts,)\n",
    "bow_start_preds = lr_bow.predict(dev_start_counts)\n",
    "# print(\"\\n--- BoW on START segment only ---\")\n",
    "print_results(dev_labels, bow_start_preds, \"BoW Segmented_START\", False)\n",
    "\n",
    "# MIDDLE\n",
    "dev_middle_counts = count_vectorizer.transform(dev_middle_texts)\n",
    "bow_middle_preds = lr_bow.predict(dev_middle_counts)\n",
    "# print(\"\\n--- BoW on MIDDLE segment only ---\")\n",
    "print_results(dev_labels, bow_middle_preds, \"BoW Segmented_MIDDLE\", False)\n",
    "\n",
    "# END\n",
    "dev_end_counts = count_vectorizer.transform(dev_end_texts)\n",
    "bow_end_preds = lr_bow.predict(dev_end_counts)\n",
    "# print(\"\\n--- BoW on END segment only ---\")\n",
    "print_results(dev_labels, bow_end_preds, \"BoW Segmented_END\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835d866",
   "metadata": {},
   "source": [
    "## Evaluate Word2Vec on Segmented Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0efcd5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Word2Vec Logistic Regression: Position-based Evaluation (NO retraining) ===\n",
      "=== Overall (Macro Avg) ===\n",
      "               Model  Precision   Recall       F1  Accuracy\n",
      "            BoW & LR   0.380262 0.372645 0.373144  0.363395\n",
      "       Word2Vec & LR   0.461446 0.478161 0.455341  0.453581\n",
      " BoW Segmented_START   0.414294 0.320851 0.275773  0.323607\n",
      "BoW Segmented_MIDDLE   0.405777 0.314621 0.274071  0.318302\n",
      "   BoW Segmented_END   0.341373 0.301432 0.271661  0.307692\n",
      " W2V Segmented_START   0.409452 0.430841 0.409294  0.411141\n",
      "W2V Segmented_MIDDLE   0.427968 0.456468 0.428019  0.432361\n",
      "   W2V Segmented_END   0.388004 0.411518 0.388873  0.389920\n",
      "\n",
      "=== Per Emotion (Class) Metrics ===\n",
      "Angry:\n",
      "               Model Emotion  Precision   Recall       F1\n",
      "            BoW & LR   Angry   0.492958 0.492958 0.492958\n",
      "       Word2Vec & LR   Angry   0.612903 0.802817 0.695122\n",
      " BoW Segmented_START   Angry   0.575758 0.267606 0.365385\n",
      "BoW Segmented_MIDDLE   Angry   0.562500 0.253521 0.349515\n",
      "   BoW Segmented_END   Angry   0.441176 0.211268 0.285714\n",
      " W2V Segmented_START   Angry   0.505155 0.690141 0.583333\n",
      "W2V Segmented_MIDDLE   Angry   0.544554 0.774648 0.639535\n",
      "   W2V Segmented_END   Angry   0.520833 0.704225 0.598802\n",
      "\n",
      "Happy:\n",
      "               Model Emotion  Precision   Recall       F1\n",
      "            BoW & LR   Happy   0.456790 0.349057 0.395722\n",
      "       Word2Vec & LR   Happy   0.480392 0.462264 0.471154\n",
      " BoW Segmented_START   Happy   0.600000 0.113208 0.190476\n",
      "BoW Segmented_MIDDLE   Happy   0.538462 0.132075 0.212121\n",
      "   BoW Segmented_END   Happy   0.414634 0.160377 0.231293\n",
      " W2V Segmented_START   Happy   0.434343 0.405660 0.419512\n",
      "W2V Segmented_MIDDLE   Happy   0.474227 0.433962 0.453202\n",
      "   W2V Segmented_END   Happy   0.401709 0.443396 0.421525\n",
      "\n",
      "Relaxed:\n",
      "               Model Emotion  Precision   Recall       F1\n",
      "            BoW & LR Relaxed   0.305344 0.396040 0.344828\n",
      "       Word2Vec & LR Relaxed   0.335821 0.445545 0.382979\n",
      " BoW Segmented_START Relaxed   0.295374 0.821782 0.434555\n",
      "BoW Segmented_MIDDLE Relaxed   0.279720 0.792079 0.413437\n",
      "   BoW Segmented_END Relaxed   0.291498 0.712871 0.413793\n",
      " W2V Segmented_START Relaxed   0.346457 0.435644 0.385965\n",
      "W2V Segmented_MIDDLE Relaxed   0.346154 0.445545 0.389610\n",
      "   W2V Segmented_END Relaxed   0.289474 0.326733 0.306977\n",
      "\n",
      "Sad:\n",
      "               Model Emotion  Precision   Recall       F1\n",
      "            BoW & LR     Sad   0.265957 0.252525 0.259067\n",
      "       Word2Vec & LR     Sad   0.416667 0.202020 0.272109\n",
      " BoW Segmented_START     Sad   0.186047 0.080808 0.112676\n",
      "BoW Segmented_MIDDLE     Sad   0.242424 0.080808 0.121212\n",
      "   BoW Segmented_END     Sad   0.218182 0.121212 0.155844\n",
      " W2V Segmented_START     Sad   0.351852 0.191919 0.248366\n",
      "W2V Segmented_MIDDLE     Sad   0.346939 0.171717 0.229730\n",
      "   W2V Segmented_END     Sad   0.340000 0.171717 0.228188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Word2Vec Logistic Regression: Position-based Evaluation (NO retraining) ===\")\n",
    "\n",
    "# START\n",
    "dev_start_vecs = [vec_for_doc(word_tokenize(x)) for x in dev_start_texts]\n",
    "w2v_start_preds = lr_w2v.predict(dev_start_vecs)\n",
    "# print(\"\\n--- W2V on START segment only ---\")\n",
    "print_results(dev_labels, w2v_start_preds, \"W2V Segmented_START\", False)\n",
    "\n",
    "# MIDDLE\n",
    "dev_middle_vecs = [vec_for_doc(word_tokenize(x)) for x in dev_middle_texts]\n",
    "w2v_middle_preds = lr_w2v.predict(dev_middle_vecs)\n",
    "# print(\"\\n--- W2V on MIDDLE segment only ---\")\n",
    "print_results(dev_labels, w2v_middle_preds, \"W2V Segmented_MIDDLE\", False)\n",
    "\n",
    "# END\n",
    "dev_end_vecs = [vec_for_doc(word_tokenize(x)) for x in dev_end_texts]\n",
    "w2v_end_preds = lr_w2v.predict(dev_end_vecs)\n",
    "# print(\"\\n--- W2V on END segment only ---\")\n",
    "print_results(dev_labels, w2v_end_preds, \"W2V Segmented_END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a5a0d",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8275c4c9-0c1f-4969-a64a-e055131ce792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset, tokenizer, max_length: int = 256):\n",
    "    def _tok(batch):\n",
    "        return tokenizer(\n",
    "            batch[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "    tokenized = dataset.map(_tok, batched=True)\n",
    "    tokenized = tokenized.remove_columns([\"text\"])\n",
    "    tokenized.set_format(type=\"torch\")\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "def train_and_eval_transformer(\n",
    "    model_name: str,\n",
    "    train_dataset: Dataset,\n",
    "    dev_dataset: Dataset,\n",
    "    output_dir: str,\n",
    "    num_epochs: int,\n",
    "    learning_rate: float,\n",
    "    train_bs: int,\n",
    "    eval_bs: int,\n",
    "    set_pad_token_eos: bool = False,\n",
    "):\n",
    "    print(f\"=== Fine-tuning {model_name} ===\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    if set_pad_token_eos:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    tokenized_train = tokenize_dataset(train_dataset, tokenizer)\n",
    "    tokenized_dev = tokenize_dataset(dev_dataset, tokenizer)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(EMOTIONS),\n",
    "        label2id=label2id,\n",
    "        id2label=id2label,\n",
    "        ignore_mismatched_sizes=True,\n",
    "    )\n",
    "\n",
    "    if set_pad_token_eos:\n",
    "        model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=num_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=train_bs,\n",
    "        per_device_eval_batch_size=eval_bs,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        logging_steps=16,\n",
    "        log_level=\"error\",\n",
    "        report_to=\"none\",\n",
    "        save_strategy=\"epoch\",\n",
    "        dataloader_pin_memory=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_dev,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"{model_name} dev results:\", eval_results)\n",
    "\n",
    "    pred_output = trainer.predict(tokenized_dev)\n",
    "    logits = pred_output.predictions\n",
    "    pred_ids = np.argmax(logits, axis=-1)\n",
    "    pred_labels = [id2label[i] for i in pred_ids]\n",
    "\n",
    "    print(f\"{model_name} classification report:\")\n",
    "    print_results(dev_labels, pred_labels, model_name)\n",
    "\n",
    "    return trainer, eval_results, pred_labels\n",
    "\n",
    "def eval_transformer_on_segments(model_name: str, trainer: Trainer):\n",
    "    \"\"\"\n",
    "    Evaluate a fine-tuned transformer (trainer) on START/MIDDLE/END\n",
    "    segments of the dev set, without retraining.\n",
    "    \"\"\"\n",
    "    tokenizer = trainer.tokenizer\n",
    "\n",
    "    for seg in [\"start\", \"middle\", \"end\"]:\n",
    "        # Build segmented dev texts\n",
    "        seg_texts = [get_segment(t, seg) for t in dev_texts]\n",
    "\n",
    "        # Build a segmented dev Dataset with same labels\n",
    "        seg_dev_ds = Dataset.from_dict(\n",
    "            {\n",
    "                \"text\": seg_texts,\n",
    "                \"label\": [label2id[l] for l in dev_labels],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Tokenize segmented dataset\n",
    "        tokenized_seg_dev = tokenize_dataset(seg_dev_ds, tokenizer)\n",
    "\n",
    "        # Predict\n",
    "        pred_output = trainer.predict(tokenized_seg_dev)\n",
    "        logits = pred_output.predictions\n",
    "        pred_ids = np.argmax(logits, axis=-1)\n",
    "        pred_labels = [id2label[i] for i in pred_ids]\n",
    "\n",
    "        print(f\"\\n=== {model_name} on {seg.upper()} segment only ===\")\n",
    "        # print_results(dev_labels, pred_labels, model_name, False)\n",
    "        if (seg == \"end\"):\n",
    "            print_results(dev_labels, pred_labels, model_name)\n",
    "        else:\n",
    "            print_results(dev_labels, pred_labels, model_name, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d4e43",
   "metadata": {},
   "source": [
    "## Distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe4e592e-e7ad-4d23-b757-580470945074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fine-tuning distilbert/distilbert-base-uncased ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef984c3beaf4c329d5f0becdaf09e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13c8cbb92164ddd85de727f43aacd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_45776\\2045020497.py:63: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4044, 'grad_norm': 2.96364426612854, 'learning_rate': 4.75e-05, 'epoch': 0.16}\n",
      "{'loss': 1.4013, 'grad_norm': 4.3935956954956055, 'learning_rate': 4.483333333333333e-05, 'epoch': 0.32}\n",
      "{'loss': 1.4317, 'grad_norm': 4.00533390045166, 'learning_rate': 4.216666666666667e-05, 'epoch': 0.48}\n",
      "{'loss': 1.4107, 'grad_norm': 2.9911444187164307, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.64}\n",
      "{'loss': 1.3998, 'grad_norm': 3.5910935401916504, 'learning_rate': 3.683333333333334e-05, 'epoch': 0.8}\n",
      "{'loss': 1.4004, 'grad_norm': 2.920949935913086, 'learning_rate': 3.4166666666666666e-05, 'epoch': 0.96}\n",
      "{'eval_loss': 1.387216567993164, 'eval_precision': 0.06697612732095491, 'eval_recall': 0.25, 'eval_f1': 0.10564853556485355, 'eval_accuracy': 0.26790450928381965, 'eval_runtime': 84.7773, 'eval_samples_per_second': 4.447, 'eval_steps_per_second': 1.121, 'epoch': 1.0}\n",
      "{'loss': 1.404, 'grad_norm': 2.00425386428833, 'learning_rate': 3.15e-05, 'epoch': 1.12}\n",
      "{'loss': 1.3717, 'grad_norm': 3.418452739715576, 'learning_rate': 2.8833333333333334e-05, 'epoch': 1.28}\n",
      "{'loss': 1.3448, 'grad_norm': 2.7534596920013428, 'learning_rate': 2.6166666666666668e-05, 'epoch': 1.44}\n",
      "{'loss': 1.2963, 'grad_norm': 4.127481937408447, 'learning_rate': 2.35e-05, 'epoch': 1.6}\n",
      "{'loss': 1.2972, 'grad_norm': 8.199294090270996, 'learning_rate': 2.0833333333333336e-05, 'epoch': 1.76}\n",
      "{'loss': 1.2972, 'grad_norm': 15.322639465332031, 'learning_rate': 1.8166666666666667e-05, 'epoch': 1.92}\n",
      "{'eval_loss': 1.3779807090759277, 'eval_precision': 0.3071383349161127, 'eval_recall': 0.3912907202226999, 'eval_f1': 0.29256092495153696, 'eval_accuracy': 0.34748010610079577, 'eval_runtime': 60.1614, 'eval_samples_per_second': 6.266, 'eval_steps_per_second': 1.579, 'epoch': 2.0}\n",
      "{'loss': 1.1868, 'grad_norm': 7.8245697021484375, 'learning_rate': 1.55e-05, 'epoch': 2.08}\n",
      "{'loss': 1.13, 'grad_norm': 6.110537052154541, 'learning_rate': 1.2833333333333333e-05, 'epoch': 2.24}\n",
      "{'loss': 0.9953, 'grad_norm': 11.7296724319458, 'learning_rate': 1.0166666666666667e-05, 'epoch': 2.4}\n",
      "{'loss': 1.0934, 'grad_norm': 6.505113124847412, 'learning_rate': 7.5e-06, 'epoch': 2.56}\n",
      "{'loss': 0.9827, 'grad_norm': 5.049815654754639, 'learning_rate': 4.833333333333333e-06, 'epoch': 2.7199999999999998}\n",
      "{'loss': 1.0509, 'grad_norm': 8.05215072631836, 'learning_rate': 2.166666666666667e-06, 'epoch': 2.88}\n",
      "{'eval_loss': 1.1479463577270508, 'eval_precision': 0.500297450336695, 'eval_recall': 0.5095269891060326, 'eval_f1': 0.500739365807717, 'eval_accuracy': 0.493368700265252, 'eval_runtime': 88.2827, 'eval_samples_per_second': 4.27, 'eval_steps_per_second': 1.076, 'epoch': 3.0}\n",
      "{'train_runtime': 1289.5832, 'train_samples_per_second': 0.931, 'train_steps_per_second': 0.233, 'train_loss': 1.2585895729064942, 'epoch': 3.0}\n",
      "{'eval_loss': 1.1479463577270508, 'eval_precision': 0.500297450336695, 'eval_recall': 0.5095269891060326, 'eval_f1': 0.500739365807717, 'eval_accuracy': 0.493368700265252, 'eval_runtime': 93.9196, 'eval_samples_per_second': 4.014, 'eval_steps_per_second': 1.012, 'epoch': 3.0}\n",
      "distilbert/distilbert-base-uncased dev results: {'eval_loss': 1.1479463577270508, 'eval_precision': 0.500297450336695, 'eval_recall': 0.5095269891060326, 'eval_f1': 0.500739365807717, 'eval_accuracy': 0.493368700265252, 'eval_runtime': 93.9196, 'eval_samples_per_second': 4.014, 'eval_steps_per_second': 1.012, 'epoch': 3.0}\n",
      "distilbert/distilbert-base-uncased classification report:\n",
      "=== Overall (Macro Avg) ===\n",
      "                             Model  Precision   Recall       F1  Accuracy\n",
      "                          BoW & LR   0.380262 0.372645 0.373144  0.363395\n",
      "                     Word2Vec & LR   0.461446 0.478161 0.455341  0.453581\n",
      "               BoW Segmented_START   0.414294 0.320851 0.275773  0.323607\n",
      "              BoW Segmented_MIDDLE   0.405777 0.314621 0.274071  0.318302\n",
      "                 BoW Segmented_END   0.341373 0.301432 0.271661  0.307692\n",
      "               W2V Segmented_START   0.409452 0.430841 0.409294  0.411141\n",
      "              W2V Segmented_MIDDLE   0.427968 0.456468 0.428019  0.432361\n",
      "                 W2V Segmented_END   0.388004 0.411518 0.388873  0.389920\n",
      "                        DistilGPT2   0.447727 0.472649 0.417968  0.450928\n",
      "distilbert/distilbert-base-uncased   0.500297 0.509527 0.500739  0.493369\n",
      "\n",
      "=== Per Emotion (Class) Metrics ===\n",
      "Angry:\n",
      "                             Model Emotion  Precision   Recall       F1\n",
      "                          BoW & LR   Angry   0.492958 0.492958 0.492958\n",
      "                     Word2Vec & LR   Angry   0.612903 0.802817 0.695122\n",
      "               BoW Segmented_START   Angry   0.575758 0.267606 0.365385\n",
      "              BoW Segmented_MIDDLE   Angry   0.562500 0.253521 0.349515\n",
      "                 BoW Segmented_END   Angry   0.441176 0.211268 0.285714\n",
      "               W2V Segmented_START   Angry   0.505155 0.690141 0.583333\n",
      "              W2V Segmented_MIDDLE   Angry   0.544554 0.774648 0.639535\n",
      "                 W2V Segmented_END   Angry   0.520833 0.704225 0.598802\n",
      "                        DistilGPT2   Angry   0.623377 0.676056 0.648649\n",
      "                        DistilGPT2   Angry   0.750000 0.760563 0.755245\n",
      "distilbert/distilbert-base-uncased   Angry   0.732394 0.732394 0.732394\n",
      "\n",
      "Happy:\n",
      "                             Model Emotion  Precision   Recall       F1\n",
      "                          BoW & LR   Happy   0.456790 0.349057 0.395722\n",
      "                     Word2Vec & LR   Happy   0.480392 0.462264 0.471154\n",
      "               BoW Segmented_START   Happy   0.600000 0.113208 0.190476\n",
      "              BoW Segmented_MIDDLE   Happy   0.538462 0.132075 0.212121\n",
      "                 BoW Segmented_END   Happy   0.414634 0.160377 0.231293\n",
      "               W2V Segmented_START   Happy   0.434343 0.405660 0.419512\n",
      "              W2V Segmented_MIDDLE   Happy   0.474227 0.433962 0.453202\n",
      "                 W2V Segmented_END   Happy   0.401709 0.443396 0.421525\n",
      "                        DistilGPT2   Happy   0.477612 0.301887 0.369942\n",
      "                        DistilGPT2   Happy   0.500000 0.377358 0.430108\n",
      "distilbert/distilbert-base-uncased   Happy   0.529412 0.509434 0.519231\n",
      "\n",
      "Relaxed:\n",
      "                             Model Emotion  Precision   Recall       F1\n",
      "                          BoW & LR Relaxed   0.305344 0.396040 0.344828\n",
      "                     Word2Vec & LR Relaxed   0.335821 0.445545 0.382979\n",
      "               BoW Segmented_START Relaxed   0.295374 0.821782 0.434555\n",
      "              BoW Segmented_MIDDLE Relaxed   0.279720 0.792079 0.413437\n",
      "                 BoW Segmented_END Relaxed   0.291498 0.712871 0.413793\n",
      "               W2V Segmented_START Relaxed   0.346457 0.435644 0.385965\n",
      "              W2V Segmented_MIDDLE Relaxed   0.346154 0.445545 0.389610\n",
      "                 W2V Segmented_END Relaxed   0.289474 0.326733 0.306977\n",
      "                        DistilGPT2 Relaxed   0.357143 0.792079 0.492308\n",
      "                        DistilGPT2 Relaxed   0.340909 0.742574 0.467290\n",
      "distilbert/distilbert-base-uncased Relaxed   0.443609 0.584158 0.504274\n",
      "\n",
      "Sad:\n",
      "                             Model Emotion  Precision   Recall       F1\n",
      "                          BoW & LR     Sad   0.265957 0.252525 0.259067\n",
      "                     Word2Vec & LR     Sad   0.416667 0.202020 0.272109\n",
      "               BoW Segmented_START     Sad   0.186047 0.080808 0.112676\n",
      "              BoW Segmented_MIDDLE     Sad   0.242424 0.080808 0.121212\n",
      "                 BoW Segmented_END     Sad   0.218182 0.121212 0.155844\n",
      "               W2V Segmented_START     Sad   0.351852 0.191919 0.248366\n",
      "              W2V Segmented_MIDDLE     Sad   0.346939 0.171717 0.229730\n",
      "                 W2V Segmented_END     Sad   0.340000 0.171717 0.228188\n",
      "                        DistilGPT2     Sad   0.555556 0.050505 0.092593\n",
      "                        DistilGPT2     Sad   0.200000 0.010101 0.019231\n",
      "distilbert/distilbert-base-uncased     Sad   0.295775 0.212121 0.247059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distilbert_trainer, distilbert_results, distilbert_pred_labels = train_and_eval_transformer(\n",
    "    model_name=\"distilbert/distilbert-base-uncased\",\n",
    "    train_dataset=train_ds,\n",
    "    dev_dataset=dev_ds,\n",
    "    output_dir=\"./distilbert_musicmood\",\n",
    "    num_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    train_bs=4,\n",
    "    eval_bs=4,\n",
    "    set_pad_token_eos=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b68de",
   "metadata": {},
   "source": [
    "## Segment Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96d64d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd12b000dd964117ae53dbaf82e0d249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_transformer_on_segments(\"DistilBERT\", distilbert_trainer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPVENV2",
   "language": "python",
   "name": "nlpvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
